# {{ cookiecutter.project_name }}

{{ cookiecutter.description }}

## é¡¹ç›®ä¿¡æ¯

- **é¡¹ç›®åç§°**: {{ cookiecutter.project_name }}
- **ä½œè€…**: {{ cookiecutter.author_name }} ({{ cookiecutter.author_email }})
- **æ•°æ®æº**: {{ cookiecutter.data_file }}
- **æ‰¹å¤„ç†å¤§å°**: {{ cookiecutter.batch_size }}

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. å‡†å¤‡æ•°æ®

å°†ä½ çš„æ•°æ®æ–‡ä»¶æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œå‘½åä¸º `{{ cookiecutter.data_file }}`

æ•°æ®æ–‡ä»¶åº”åŒ…å«ä»¥ä¸‹åŸºæœ¬åˆ—:
- ä¸»é”®å­—æ®µ(å¦‚ `id`)  
- ä¸šåŠ¡ç›¸å…³å­—æ®µ(æ ¹æ®ä½ çš„éœ€æ±‚)

### 3. ä¿®æ”¹ä¸šåŠ¡é€»è¾‘

æ‰“å¼€ `main.ipynb`ï¼Œä½ éœ€è¦ä¿®æ”¹ä»¥ä¸‹3ä¸ªæ–¹æ³•:

#### 3.1 å®šä¹‰è¡¨ç»“æ„ (`define_schema`)

```python
def define_schema(self) -> Dict[str, list]:
    return {
        'control_fields': [
            'is_processed',    # ç³»ç»Ÿå­—æ®µï¼Œå‹¿åˆ 
            'retry_count'      # ç³»ç»Ÿå­—æ®µï¼Œå‹¿åˆ 
        ],
        'result_fields': [
            'your_result1',    # æ›¿æ¢ä¸ºä½ çš„ç»“æœå­—æ®µ
            'your_result2',    # æ›¿æ¢ä¸ºä½ çš„ç»“æœå­—æ®µ
        ]
    }
```

#### 3.2 å®ç°ä¸šåŠ¡é€»è¾‘ (`process_business_logic`)

```python  
def process_business_logic(self, batch_data: pd.DataFrame) -> pd.DataFrame:
    # å¦‚æœéœ€è¦è°ƒç”¨å¤–éƒ¨APIï¼Œå¯ä»¥ä½¿ç”¨:
    # external_data = self.fetch_external_data(batch_data)
    
    # å®ç°ä½ çš„æ ¸å¿ƒä¸šåŠ¡å¤„ç†é€»è¾‘
    for idx, row in batch_data.iterrows():
        # æ‰§è¡Œæ•°æ®æ¯”å¯¹ã€è®¡ç®—ã€åˆ¤æ–­ç­‰
        batch_data.loc[idx, 'your_result1'] = 'value1'
        batch_data.loc[idx, 'your_result2'] = 'value2'
    
    return batch_data
```

##### å¹¶è¡Œå¤„ç†ï¼ˆå¯é€‰ï¼Œæ¨èç”¨äº IO å¯†é›†åœºæ™¯ï¼‰

æä¾›ä¸€ä¸ªç®€å•çš„å¹¶è¡Œè¯­æ³•ç³– `@parallel(pool_size=5)`ï¼Œç”¨äºå°†å•æ¡ä»»åŠ¡çš„å¤„ç†å¹¶è¡ŒåŒ–ï¼š

```python
from utils import parallel, join_all

def process_business_logic(self, batch_data: pd.DataFrame) -> pd.DataFrame:
    @parallel(pool_size=5)
    def handle_one_task(row):
        # æ‰§è¡Œä½ çš„ IO/ç½‘ç»œè°ƒç”¨ç­‰è€—æ—¶æ“ä½œ
        return {
            'your_result1': 'value1',
            'your_result2': 'value2',
        }

    futures = [handle_one_task(row) for _, row in batch_data.iterrows()]
    results = join_all(futures)
    handle_one_task.pool_shutdown()

    for (idx, _), res in zip(batch_data.iterrows(), results):
        batch_data.loc[idx, 'your_result1'] = res.get('your_result1', '')
        batch_data.loc[idx, 'your_result2'] = res.get('your_result2', '')

    return batch_data
```

è¯´æ˜ï¼š
- `pool_size` æ§åˆ¶å¹¶å‘åº¦ï¼ˆçº¿ç¨‹æ± ï¼‰ï¼Œé€‚åˆ IO å¯†é›†ï¼ˆå¦‚ API è¯·æ±‚ï¼‰ã€‚
- `f.join()` ç­‰ä»·äº `future.result()`ï¼Œä¼šåœ¨ä»»åŠ¡å®Œæˆåè¿”å›ç»“æœã€‚
- ä½¿ç”¨å®Œæˆåè°ƒç”¨ `handle_one_task.pool_shutdown()` ä»¥é‡Šæ”¾çº¿ç¨‹èµ„æºã€‚

#### 3.3 (å¯é€‰) å®ç°APIè°ƒç”¨ (`fetch_external_data`)

```python
def fetch_external_data(self, batch_data: pd.DataFrame) -> Dict[str, Any]:
    # å¦‚æœéœ€è¦è°ƒç”¨å¤–éƒ¨APIï¼Œè¯·å®ç°æ­¤æ–¹æ³•
    # ä¾‹å¦‚: æ‰¹é‡æŸ¥è¯¢è®¢å•ã€ç”¨æˆ·ä¿¡æ¯ç­‰
    return {}
```

### 4. è¿è¡Œå¤„ç†

åœ¨Jupyterä¸­æ‰§è¡Œæœ€åçš„è¿è¡Œå•å…ƒæ ¼å³å¯:

```python
processor = YourProcessor(...)
processor.run()
```

## æ¡†æ¶ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
- âœ… **æ ‡å‡†åŒ–æµç¨‹**: æ•°æ®å¯¼å…¥ â†’ æ‰¹å¤„ç† â†’ ç»“æœå›å¡«
- âœ… **æ–­ç‚¹ç»­ä¼ **: åŸºäºæ¸¸æ ‡IDå®ç°æ–­ç‚¹ç»­ä¼ 
- âœ… **é”™è¯¯é‡è¯•**: è‡ªåŠ¨é‡è¯•å¤±è´¥çš„è®°å½•
- âœ… **è¿›åº¦è·Ÿè¸ª**: å®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦
- âœ… **ç»“æœå¯¼å‡º**: æ”¯æŒCSV/Excelæ ¼å¼å¯¼å‡º

### é«˜çº§ç‰¹æ€§
- ğŸš€ **ç¼“å­˜æ”¯æŒ**: {% if cookiecutter.enable_cache == 'y' %}å·²å¯ç”¨{% else %}å·²ç¦ç”¨{% endif %}APIè°ƒç”¨ç¼“å­˜
- ğŸ“Š **ç»Ÿè®¡æŠ¥å‘Š**: è¯¦ç»†çš„å¤„ç†ç»Ÿè®¡ä¿¡æ¯
- ğŸ”§ **çµæ´»é…ç½®**: å¯é…ç½®æ‰¹æ¬¡å¤§å°ã€é‡è¯•æ¬¡æ•°ç­‰
- ğŸ“ **å®Œæ•´æ—¥å¿—**: è¯¦ç»†çš„å¤„ç†æ—¥å¿—è®°å½•

## é…ç½®è¯´æ˜

ä¸»è¦é…ç½®é¡¹åœ¨ `config.py` ä¸­:

```python
# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'batch_size': {{ cookiecutter.batch_size }},     # æ‰¹å¤„ç†å¤§å°
    'max_retries': {{ cookiecutter.max_retries }}    # æœ€å¤§é‡è¯•æ¬¡æ•°
}

# ç¼“å­˜é…ç½®
CACHE_CONFIG = {
    'enable': {{ 'True' if cookiecutter.enable_cache == 'y' else 'False' }},
    'size': {{ cookiecutter.cache_size }}
}
```

## å¤„ç†æµç¨‹

```mermaid
graph TD
    A[å¯¼å…¥æ•°æ®] --> B[åˆå§‹åŒ–æ§åˆ¶å­—æ®µ]
    B --> C[æ‰¹é‡æŸ¥è¯¢æœªå¤„ç†æ•°æ®]
    C --> D[æ‰§è¡Œæ‰¹é‡ä¸šåŠ¡é€»è¾‘]
    D --> E[æ›´æ–°ç»“æœåˆ°æ•°æ®åº“]
    E --> F{è¿˜æœ‰æœªå¤„ç†æ•°æ®?}
    F -->|æ˜¯| C
    F -->|å¦| G[å¤„ç†å®Œæˆ]
```

## ç¤ºä¾‹é¡¹ç›®

å‚è€ƒ `example.ipynb` æŸ¥çœ‹å®Œæ•´çš„ä¸šç»©å½’å› åˆ¤æ–­ç¤ºä¾‹ï¼ŒåŒ…å«:

- è®¢å•å½’å› APIè°ƒç”¨
- å‘˜å·¥ä¿¡æ¯æŸ¥è¯¢  
- ä¸šç»©åŒ¹é…åˆ¤æ–­
- ç»“æœç»Ÿè®¡åˆ†æ

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¤„ç†å¤§æ•°æ®é‡?
è°ƒæ•´ `batch_size` å‚æ•°ï¼Œå»ºè®®50-200ä¹‹é—´

### Q2: å¤„ç†å¤±è´¥æ€ä¹ˆåŠ?
æ¡†æ¶ä¼šè‡ªåŠ¨é‡è¯•ï¼Œå¯é€šè¿‡ `max_retries` é…ç½®é‡è¯•æ¬¡æ•°

### Q3: å¦‚ä½•æŸ¥çœ‹å¤„ç†è¿›åº¦?
è¿è¡Œè¿‡ç¨‹ä¸­ä¼šå®æ—¶æ‰“å°è¿›åº¦ä¿¡æ¯ï¼Œä¹Ÿå¯ä»¥è°ƒç”¨ `get_statistics()` æŸ¥çœ‹

### Q4: å¦‚ä½•æš‚åœå’Œæ¢å¤å¤„ç†?
ç›´æ¥åœæ­¢è¿è¡Œï¼Œä¸‹æ¬¡å¯åŠ¨ä¼šä»ä¸Šæ¬¡çš„ä½ç½®ç»§ç»­å¤„ç†

### Q5: å¦‚ä½•å¤„ç†å¤±è´¥é‡è¯•?
æ¡†æ¶æ”¯æŒæ™ºèƒ½çš„å¤±è´¥é‡è¯•æœºåˆ¶ï¼š

**åœºæ™¯**: å¤„ç†äº†100ä¸ªæ‰¹æ¬¡ï¼Œå…¶ä¸­2ä¸ªæ‰¹æ¬¡å¤±è´¥ï¼Œå¦‚ä½•é‡è¯•ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**:
1. ç›´æ¥é‡æ–°è¿è¡Œç›¸åŒçš„ `processor.run()` ä»£ç 
2. æ¡†æ¶ä¼šè‡ªåŠ¨æ£€æµ‹åˆ°å·²å­˜åœ¨çš„æ•°æ®è¡¨
3. ç³»ç»Ÿä¼šè¯¢é—®ä½ çš„é€‰æ‹©ï¼š
   - `[s] è·³è¿‡å¯¼å…¥` - **æ¨èé€‰æ‹©**ï¼Œç›´æ¥å¤„ç†å¤±è´¥çš„è®°å½•
   - `[r] è¦†ç›–å¯¼å…¥` - åˆ é™¤æ‰€æœ‰æ•°æ®ï¼Œé‡æ–°å¼€å§‹

**æœ€ä½³å®è·µ**:
```python
# å¤±è´¥é‡è¯•æ—¶ï¼Œé€‰æ‹©"è·³è¿‡å¯¼å…¥"
processor.run()  # ç³»ç»Ÿè¯¢é—®æ—¶é€‰æ‹© [s]

# å¦‚éœ€å¼ºåˆ¶é‡æ–°å¼€å§‹ï¼Œå¯ä»¥ä½¿ç”¨:
processor.run()  # ç³»ç»Ÿè¯¢é—®æ—¶é€‰æ‹© [r]
```

**æ³¨æ„**: 
- è·³è¿‡å¯¼å…¥ä¼šä¿ç•™å·²æˆåŠŸå¤„ç†çš„è®°å½•ï¼Œåªé‡è¯•å¤±è´¥çš„æ‰¹æ¬¡
- è¦†ç›–å¯¼å…¥ä¼šåˆ é™¤æ‰€æœ‰è®°å½•ï¼Œä»å¤´å¼€å§‹å¤„ç†
- æ¡†æ¶ä¼šè‡ªåŠ¨è·³è¿‡ `retry_count >= max_retries` çš„è®°å½•

## è®¸å¯è¯

MIT License
